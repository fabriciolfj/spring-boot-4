# Spring Batch - Projeto Demonstrativo

Projeto completo demonstrando os conceitos e componentes do Spring Batch atravÃ©s de um caso prÃ¡tico de processamento de transaÃ§Ãµes financeiras.

## ğŸ“‹ Ãndice

1. [O que Ã© Spring Batch](#o-que-Ã©-spring-batch)
2. [Componentes Principais](#componentes-principais)
3. [Arquitetura do Projeto](#arquitetura-do-projeto)
4. [Como Executar](#como-executar)
5. [Testando o Projeto](#testando-o-projeto)
6. [Entendendo o Fluxo](#entendendo-o-fluxo)

## ğŸ¯ O que Ã© Spring Batch

Spring Batch Ã© um framework para processamento em lote (batch) de grandes volumes de dados. Ele fornece:

- **Chunk-oriented processing**: Processa dados em blocos (chunks)
- **Transaction management**: Gerencia transaÃ§Ãµes automaticamente
- **Job repository**: MantÃ©m histÃ³rico de execuÃ§Ãµes
- **Restart/Retry**: Permite reiniciar jobs e retentar operaÃ§Ãµes falhas
- **Skip logic**: Pula registros com erro sem parar o processamento
- **Parallel processing**: Suporta processamento paralelo

## ğŸ”§ Componentes Principais

### 1. Job
```
Job = Orquestra todo o processo batch
  â””â”€â”€ Step 1
  â””â”€â”€ Step 2
  â””â”€â”€ Step N
```

**Responsabilidades:**
- Define a sequÃªncia de steps
- Configura listeners globais
- Define polÃ­ticas de restart
- Gerencia parÃ¢metros de execuÃ§Ã£o

### 2. Step
```
Step = Uma fase do processamento
  â””â”€â”€ Chunk (tamanho configurÃ¡vel)
      â”œâ”€â”€ Read (ItemReader)
      â”œâ”€â”€ Process (ItemProcessor)
      â””â”€â”€ Write (ItemWriter)
```

**Responsabilidades:**
- Define o tamanho do chunk
- Configura reader, processor, writer
- Define polÃ­ticas de erro (skip, retry)
- Gerencia transaÃ§Ãµes

### 3. ItemReader
```java
interface ItemReader<T> {
    T read() throws Exception;
}
```

**ImplementaÃ§Ãµes comuns:**
- `FlatFileItemReader`: LÃª arquivos CSV, TXT
- `JdbcCursorItemReader`: LÃª de banco usando cursor
- `JpaPagingItemReader`: LÃª com paginaÃ§Ã£o JPA
- `KafkaItemReader`: LÃª de tÃ³picos Kafka

**No projeto:**
- LÃª arquivo CSV com transaÃ§Ãµes
- Mapeia cada linha para objeto TransacaoCSV
- Pula primeira linha (cabeÃ§alho)

### 4. ItemProcessor
```java
interface ItemProcessor<I,O> {
    O process(I item) throws Exception;
}
```

**Responsabilidades:**
- Transformar dados (I â†’ O)
- Validar dados
- Enriquecer informaÃ§Ãµes
- Filtrar (retorna null)

**No projeto:**
- Valida duplicatas
- Valida valores mÃ¡ximos por tipo
- Calcula taxas
- Converte tipos de dados
- Filtra registros invÃ¡lidos

### 5. ItemWriter
```java
interface ItemWriter<T> {
    void write(Chunk<? extends T> items);
}
```

**ImplementaÃ§Ãµes comuns:**
- `JpaItemWriter`: Grava usando JPA
- `JdbcBatchItemWriter`: Grava com JDBC batch
- `FlatFileItemWriter`: Grava em arquivo
- `KafkaItemWriter`: Envia para Kafka

**No projeto:**
- Grava transaÃ§Ãµes no banco H2
- Usa JPA para batch inserts
- Adiciona logging customizado

### 6. JobOperator (Spring Batch 5.x)

```java
interface JobOperator {
    Long start(String jobName, String parameters);
    boolean stop(Long executionId);
    Long restart(Long executionId);
    Set<Long> getRunningExecutions(String jobName);
}
```

**Vantagens sobre JobLauncher:**
- API de alto nÃ­vel para gerenciamento de jobs
- Suporta operaÃ§Ãµes de controle (start, stop, restart)
- IntegraÃ§Ã£o com JobRegistry para descoberta automÃ¡tica
- Melhor para aplicaÃ§Ãµes de produÃ§Ã£o e APIs REST

**No projeto:**
- Usado no `BatchController` para iniciar jobs via REST API
- Permite parar execuÃ§Ãµes em andamento
- Facilita restart de jobs que falharam
- Fornece listagem de execuÃ§Ãµes

### 7. JobRepository

Armazena metadados sobre execuÃ§Ãµes:
- `BATCH_JOB_INSTANCE`: InstÃ¢ncias Ãºnicas do job
- `BATCH_JOB_EXECUTION`: Cada execuÃ§Ã£o do job
- `BATCH_STEP_EXECUTION`: Cada execuÃ§Ã£o de step
- `BATCH_JOB_EXECUTION_PARAMS`: ParÃ¢metros usados

### 8. Chunk Processing

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Chunk Size = 100                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. Read 100 items                      â”‚
â”‚  2. Process each item                   â”‚
â”‚  3. Write all 100 items                 â”‚
â”‚  4. Commit transaction                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Vantagens:**
- Processamento eficiente de grandes volumes
- Commits periÃ³dicos (nÃ£o sobrecarrega memÃ³ria)
- Rollback granular em caso de erro

## ğŸ—ï¸ Arquitetura do Projeto

```
src/main/java/com/exemplo/batch/
â”œâ”€â”€ SpringBatchApplication.java          # Classe principal
â”œâ”€â”€ config/
â”‚   â””â”€â”€ BatchJobConfig.java              # ConfiguraÃ§Ã£o do Job e Step
â”œâ”€â”€ controller/
â”‚   â””â”€â”€ BatchController.java             # API REST para executar job
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ TransacaoCSV.java                # DTO de entrada (CSV)
â”‚   â””â”€â”€ Transacao.java                   # Entidade JPA (saÃ­da)
â”œâ”€â”€ repository/
â”‚   â””â”€â”€ TransacaoRepository.java         # Repository JPA
â”œâ”€â”€ reader/
â”‚   â””â”€â”€ TransacaoItemReaderConfig.java   # ConfiguraÃ§Ã£o do Reader
â”œâ”€â”€ processor/
â”‚   â””â”€â”€ TransacaoItemProcessor.java      # LÃ³gica de processamento
â”œâ”€â”€ writer/
â”‚   â””â”€â”€ TransacaoItemWriterConfig.java   # ConfiguraÃ§Ã£o do Writer
â””â”€â”€ listener/
    â”œâ”€â”€ JobCompletionNotificationListener.java
    â””â”€â”€ StepNotificationListener.java

src/main/resources/
â”œâ”€â”€ application.yml                      # ConfiguraÃ§Ãµes
â””â”€â”€ data/
    â””â”€â”€ transacoes.csv                   # Arquivo de entrada
```

## ğŸš€ Como Executar

### PrÃ©-requisitos
- Java 21+
- Maven 3.6+

### Passo 1: Compilar o projeto
```bash
cd spring-batch-demo
mvn clean package
```

### Passo 2: Executar a aplicaÃ§Ã£o
```bash
mvn spring-boot:run
```

### Passo 3: Executar o job
```bash
curl -X POST http://localhost:8080/api/batch/processar
```

Ou acesse o H2 Console para verificar os dados:
- URL: http://localhost:8080/h2-console
- JDBC URL: jdbc:h2:mem:batchdb
- User: sa
- Password: (deixe em branco)

## ğŸ§ª Testando o Projeto

### Teste 1: ExecuÃ§Ã£o Normal
```bash
# Executar o job
curl -X POST http://localhost:8080/api/batch/processar

# Resposta esperada:
# {
#   "executionId": 1,
#   "jobName": "processarTransacoesJob",
#   "status": "STARTED",
#   "startTime": "2024-12-05T10:00:00",
#   "parameters": "executadoEm=1733400000000,requisitante=API-REST"
# }

# Verificar status da execuÃ§Ã£o (substitua {executionId} pelo ID retornado)
curl http://localhost:8080/api/batch/status/1

# Listar execuÃ§Ãµes recentes
curl http://localhost:8080/api/batch/executions?limit=10

# Parar uma execuÃ§Ã£o (se necessÃ¡rio)
curl -X POST http://localhost:8080/api/batch/stop/1

# Reiniciar uma execuÃ§Ã£o falha
curl -X POST http://localhost:8080/api/batch/restart/1
```

### Teste 2: Verificar Dados no Banco
```sql
-- Conecte ao H2 Console
SELECT * FROM transacoes;

-- Verificar taxas aplicadas
SELECT tipo, AVG(taxa_aplicada) as taxa_media 
FROM transacoes 
GROUP BY tipo;

-- Verificar total por tipo
SELECT tipo, COUNT(*), SUM(valor) as total
FROM transacoes 
GROUP BY tipo;
```

### Teste 3: Verificar Metadados do Batch
```sql
-- HistÃ³rico de execuÃ§Ãµes
SELECT * FROM BATCH_JOB_EXECUTION;

-- Detalhes dos steps
SELECT * FROM BATCH_STEP_EXECUTION;

-- ParÃ¢metros usados
SELECT * FROM BATCH_JOB_EXECUTION_PARAMS;
```

## ğŸ“Š Entendendo o Fluxo

### Fluxo Completo de ExecuÃ§Ã£o

```
1. API recebe POST /api/batch/processar
   â†“
2. JobLauncher.run(job, parameters)
   â†“
3. JobListener.beforeJob()
   â†“
4. Step Ã© executado:
   â”œâ”€â”€ StepListener.beforeStep()
   â”œâ”€â”€ Loop de Chunks:
   â”‚   â”œâ”€â”€ Read 100 items (FlatFileItemReader)
   â”‚   â”œâ”€â”€ Process each item (TransacaoItemProcessor)
   â”‚   â”‚   â”œâ”€â”€ Valida duplicata
   â”‚   â”‚   â”œâ”€â”€ Valida valor
   â”‚   â”‚   â”œâ”€â”€ Calcula taxa
   â”‚   â”‚   â””â”€â”€ Retorna Transacao (ou null para filtrar)
   â”‚   â”œâ”€â”€ Write chunk (JpaItemWriter)
   â”‚   â””â”€â”€ Commit transaction
   â””â”€â”€ StepListener.afterStep()
   â†“
5. JobListener.afterJob()
   â†“
6. Retorna JobExecution com estatÃ­sticas
```

### Processamento de um Item

```java
// 1. LEITURA (ItemReader)
TransacaoCSV csv = reader.read();
// csv = {id="TRX-001", tipo="PIX", valor="R$ 150,00", ...}

// 2. PROCESSAMENTO (ItemProcessor)
Transacao transacao = processor.process(csv);
// - Parse valor: "R$ 150,00" â†’ BigDecimal(150.00)
// - Calcula taxa PIX: 0% â†’ BigDecimal(0.00)
// - Converte data: "2024-12-01 10:30:00" â†’ LocalDateTime
// - Retorna: Transacao{valor=150.00, taxa=0.00, liquido=150.00}

// 3. ESCRITA (ItemWriter apÃ³s acumular 100 itens)
writer.write(chunk); // Grava 100 transaÃ§Ãµes de uma vez
```

### Tratamento de Erros

```
Item com erro durante processamento:
  â†“
Tentativa 1: FALHOU
  â†“
Tentativa 2: FALHOU (retry)
  â†“
Tentativa 3: FALHOU (retry)
  â†“
Skip item (se skip count < maxSkipCount)
  â†“
Continua processamento
```

## ğŸ“ ConfiguraÃ§Ãµes Importantes

### application.yml

```yaml
batch:
  chunk-size: 100              # Itens por chunk
  max-skip-count: 10           # MÃ¡ximo de erros permitidos
  input-file: classpath:data/transacoes.csv

spring:
  batch:
    job:
      enabled: false           # NÃ£o executa automaticamente
    jdbc:
      initialize-schema: always  # Cria tabelas do batch
```

### Chunk Size

**Muito pequeno (10):**
- âœ… Commits frequentes (menos dados perdidos em falha)
- âŒ Overhead de transaÃ§Ãµes
- âŒ Performance reduzida

**Muito grande (10000):**
- âœ… Menos overhead
- âœ… Melhor performance
- âŒ Mais dados perdidos em falha
- âŒ Maior uso de memÃ³ria

**Ideal (100-1000):**
- Balanceia performance e seguranÃ§a
- Depende do tamanho dos objetos
- Testar com dados reais

## ğŸ“ Conceitos AvanÃ§ados

### Parallel Processing
```java
@Bean
public Step parallelStep() {
    return stepBuilderFactory.get("step")
        .partitioner("slaveStep", partitioner())
        .taskExecutor(taskExecutor())
        .build();
}
```

### Conditional Flow
```java
@Bean
public Job conditionalJob() {
    return jobBuilderFactory.get("job")
        .start(step1)
        .on("COMPLETED").to(step2)
        .from(step1).on("FAILED").to(step3)
        .end()
        .build();
}
```

### Multiple Data Sources
```java
@Bean
public Step multiSourceStep() {
    return stepBuilderFactory.get("step")
        .chunk(100)
        .reader(compositeItemReader())  // LÃª de mÃºltiplas fontes
        .processor(processor)
        .writer(writer)
        .build();
}
```

## ğŸ“š PrÃ³ximos Passos

1. **Adicionar scheduling**: Use `@Scheduled` para executar automaticamente
2. **Implementar partitioning**: Processe em paralelo
3. **Adicionar notificaÃ§Ãµes**: Email/Slack ao terminar job
4. **MÃ©tricas**: Integrar com Micrometer/Prometheus
5. **Testes**: Adicionar testes unitÃ¡rios e de integraÃ§Ã£o

## ğŸ”— ReferÃªncias

- [Spring Batch Docs](https://spring.io/projects/spring-batch)
- [Spring Batch Reference](https://docs.spring.io/spring-batch/docs/current/reference/html/)
- [Baeldung Spring Batch](https://www.baeldung.com/spring-batch)

## ğŸ¤ DÃºvidas Comuns

**P: Quando usar Spring Batch vs processamento sÃ­ncrono?**
R: Use batch para volumes grandes (>1000 registros), processamento agendado, ou quando nÃ£o precisa de resposta imediata.

**P: Como reiniciar um job que falhou?**
R: Spring Batch mantÃ©m o estado. Basta executar novamente com os mesmos parÃ¢metros.

**P: Posso processar em paralelo?**
R: Sim! Use partitioning ou multi-threaded steps.

**P: Como monitorar jobs em produÃ§Ã£o?**
R: Use Spring Batch Admin, mÃ©tricas do Actuator, ou integre com ferramentas de monitoring.
