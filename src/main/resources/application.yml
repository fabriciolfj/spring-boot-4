server:
  port: 9091
  shutdown: GRACEFUL
  tomcat:
    connection-timeout: 5s
    keep-alive-timeout: 15s
    accept-count: 100
    threads:
      max: 200
      min-spare: 5

spring:
  config:
    import: vault://
  main:
    allow-bean-definition-overriding: true
  aot:
    repositories:
      enabled: true
  data:
    redis:
      host: localhost
      port: 6379
      database: 12
      password: redis123
      lettuce:
        pool:
          max-active: 8
          max-wait:  -1ms
          max-idle: 8
          min-idle: 2
        shutdown-timeout: 100ms
      ssl:
        enabled: false
  cache:
    type: REDIS
  rabbitmq:
    addresses: localhost
    port: 5672
    username: admin
    password: admin123
  kafka:
    streams:
      application-id: study
    bootstrap-servers:
      - localhost:29092
      - localhost:29095
      - localhost:29094
    properties:
      schema:
        registry:
          url: ${SCHEMA_REGISTRY_URL:http://localhost:8081}
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: io.confluent.kafka.serializers.KafkaAvroSerializer
      properties:
        auto.register.schemas: true
        use.latest.version: true
        # Configurações de performance
        batch.size: 16384
        linger.ms: 5
        buffer.memory: 33554432
    consumer:
      group-id: ${spring.application.name}
      auto-offset-reset: earliest
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: io.confluent.kafka.serializers.KafkaAvroDeserializer
      properties:
        specific.avro.reader: true
        schema.registry.url: http://localhost:8081
        # Configurações de performance
        fetch.min.bytes: 1024
        max.poll.records: 500
  h2:

    console:
      enabled: true
      path: /h2-console
  batch:
    job:
      enabled: true # executar automaticamente ao subir

  application:
    name: spring-four
  threads:
    virtual:
      enabled: true
  flyway:
    locations:
      - db/migration
  datasource:
    username: root
    password: root
    url: jdbc:postgresql://localhost:5432/postgres
  jpa:
    generate-ddl: false
    hibernate:
      ddl-auto: validate
    properties:
      hibernate:
        dialect: org.hibernate.dialect.PostgreSQLDialect


topic:
  product: product-topic
  details: details
  price: table-price-topic
  productDetails: product-details

cache:
  user:
    ttl: 7200
    prefix: "users:"
  product:
    ttl: 1800
    prefix: "product:"


batch:
  chunk-size: 100
  input-file: classpath:data/transacoes.csv
  max-skip-count: 10


management:
  otlp:
    metrics:
      export:
        url: http://localhost:4318/v1/metrics
  opentelemetry:
    logging:
      export:
        otlp:
          endpoint: http://localhost:4318/v1/logs
    tracing:
      export:
        otlp:
          endpoint: http://localhost:4318/v1/traces


car:
  host: http:://localhost:9000/api/v1/car